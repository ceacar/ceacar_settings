#functional programming
from functools import partial
from operator import add
def add1(x):
  return add(1,x)
#above function can be written as below
add1=partial(add,1) 

#lazy evaluation trick

#iterators
iter(x)
#calls next
next(x)

#this will only evaluate when it is called(in some sequence)
def lazy_integers(n=0):
  while True:
    yield n
  n+1
xs=lazy_integers()
[next(xs) for _ in range(10)]

#generator comprehensions
squares=(x**2 for x in lazy_integers())
next(squares)



#itertools

#count lazy eval
from itertools import count
count([start=0,[step=1]) #start, start+step, start+2*step, ...
#islice is a lazy eval of returning a part of a list
from itertools improt islice
islice(seq, [start=0], stop, [ste=1])
#copies a iterator
tee(it,[n=2])

#filter a list
list(filter(lambda x: x < 0, number_list))

#repeat
repeat(it,[n=forever])
#cycle = repeat forever
cycle(p)
#chain, chain up two or more lists
chain(a,b,...)
#accumulate, similar to reduce in scala
from itertools import accumulate
accumulate(p,[func=add])

#compress, filter based on true/false value in select_pattern
itertools.compress(input, select_pattern)

#dropwhile, drop elements when func return is true, it will break upon first unmatch, use this with sorted list
dropwhile(func, data)
#takewhile, take elements when func return is true, it will break upon first unmatch value, use this with sorted list
takewhile(func,data)
#groupby, group data by key, sort input before use groupby
#returns key and list
groupby(data, key = lambda x: x['key_value'])
#starmap, will iterate through data and use the operator provided to run accumulate against the unpaced data
startmap(operator.mul, data)
#tee(input), make deep copy of input
a,b = tee(input)
#zip_longest(input1,input2,fillvalue=None), this will zip input1 with input2 as index, and fill the empty element with fillvalue
#combinations(input, n), return a list of unique every n combination
#combinations_with_replacement(), same above but will add pair with itself
#product(input1,input2), similar to mysql inner join, returns cascadian product
#permutations(iterable, r=None), return r length of permutations of elements in the iterable, if r is none, it will return full-length permuataions




################TOOLZ###############################
#http://toolz.readthedocs.io/en/latest/api.html#toolz.functoolz.compose
#compose n functions
import toolz
>>> inc = lambda i: i + 1
import toolz.functoolz.compose(str, inc)(3)
'4'

#this is the same as f(g(h(x, y)))
toolz.functoolz.compose(f, g, h)(x, y)


#equivalent of h(g(f(data)))
toolz.functoolz.pipe(data, f, g, h)

#function that converts binary output to true or false
toolz.functoolz.complement(function_of_binary_output)

#converts any function to composable function
#toolz.functoolz.do(func, x)
>>> from toolz import compose
>>> from toolz.curried import do
>>> log = []
>>> inc = lambda x: x + 1
>>> inc = compose(inc, do(log.append))
>>> inc(1)
2
>>> inc(11)
12
>>> log
[1, 11]


  #manual implementation:
  #import functools
  #def compose(*functions):
  #    def compose2(f, g):
  #        return lambda x: f(g(x))
  #    #applies compose2 to each functions and initial value is lambda x:x  which is anonymous function of returning original
  #    return functools.reduce(compose2, functions, lambda x: x)
  ##the order the from right to left since it's a reduce function
  #composed_func = compose(str,lambda x: x*x, lambda x:x*2)
  #print composed_func(10)




#install specific version of dependency
pip install django_modeltranslation==0.4.0-beta2

#merge two json, or update one json with another json
c = {key: value for (key, value) in (a.items() + b.items())}
#loads json string to json
obj = json.loads(json_string) 

# write json to file
json.dump(data, file_obj_to_write)



#python timeit example
import timeit
def strcmp():
    if "093050201114" in "093050201114000":
        return True

print timeit.timeit(stmt = 'strcmp()',setup="from __main__ import strcmp", number=100000)



#call bash script
subprocess.check_output(["echo", "Hello World!"])
'Hello World!\n'
# or
subprocess.check_output("exit 1", shell=True)
Traceback (most recent call last):
   ...
subprocess.CalledProcessError: Command 'exit 1' returned non-zero exit status 1

# or 
from subprocess import STDOUT, check_output
output = check_output(cmd, stderr=STDOUT, timeout=seconds)

#argparse -> an wrapper to parse sys.argv
import argparse
parser = argparse.ArgumentParser()
parser.add_argument("var1", help = "var1 is the first argument here", type = int) # type is defaulted to str
parser.add_argument("-rf","--random_flag", help = "--random_flag is the demo for flag argument", action = "store_true") # set -rf and --random_flag argument. will convert this args.random_flag to true if it is set
args = parser.parser_args()
print(args.var1)

#install pip inside python script
def install(package):
    pip.main(['install',package])
packages = [boto==2.48.0,
for package in packages:
    install(package)

#python3
line_arr = line.decode('cp1252').split('|')

#force reinstall pip package
pip install --upgrade --force-reinstall

#disable ssl authenticate on urllib2
ctx = ssl.create_default_context()
ctx.check_hostname = False
ctx.verify_mode = ssl.CERT_NONE

with contextlib.closing(urllib2.urlopen(url, context = ctx)) as urlret:
  query = urlret.read()



#use python3 for py.test
#make sure you are in python3 venv
python3 -m py.test ./utest_split_by_ticker.py

#check if dir exists
os.path.exists("/home/el/myfile.txt")
#get class name from a class method def foo(self)
self.__name__
#get function name without knowing which function
import sys
this_function_name = sys._getframe().f_code.co_name

#python equivalent of pwd, current directory
import os
cwd = os.getcwd()
# create new path, >python 3.5
pathlib.Path("./scrap_cache").mkdir(parents=True, exist_ok=True)

# check file empty
es.stat(file_path).st_size == 0

# remove file
if file_path and file_path[0] != '/':
  os.remove(file_path)


#pdb debugging tip
#lunch another python interactive shell within pdb
!import code; code.interact(local=vars())

#sort python list by columns
>>> from operator import itemgetter
>>> L=[[0, 1, 'f'], [4, 2, 't'], [9, 4, 'afsd']]
>>> sorted(L, key=itemgetter(1,2))
[[9, 4, 'afsd'], [0, 1, 'f'], [4, 2, 't']]


#py.test show code coverage
pip install pytest-cov
py.test --cov-report term-missing --cov=weathertracker ./weathertracker/


#Python bit manipulation
#2 based 
int('00100001', 2) ==> 33 ==> 2**5 +1
#hex string
print "0x%x" % int('11111111', 2) => 0xff
#from ascii integer to char
chr(int('111011', 2)) => ';'
1 << 7 ==> 128


#unittest with mock
with patch('requests.get') as mock_requests:
    mock_requests.return_value="123"
    assert module1.method_to_test1("http://www.google.com") == "123"
#mock with decorator pattern
@patch('requests.get') # this will be the mockked first argument of the test case "mock1" 
def test_method2_wth(self, mock1): #this mock1 declared the @patch("request.get") above is named as "mock1"
    mock1.return_value = "123"
    assert wth.wth1("http://www.google.com") == "123"

#mock with side_effect
@patch('requests.get')
def test_method3_wth_with_sideeffect(self, mock1):

    def side_effect(*args, **kwargs): #here is the side effect mock, it will run when the mock method is called
        raise Exception("oops")

    mock1.side_effect = side_effect
    try:
        wth.wth1("http://www.google.com") == "123"
    except Exception as e:
        assert True


#full unit test example below
#code to mock
import requests
def wth1(url:str):
    res = requests.get(url)
    return res[:10]

#mocked unit test example below
import unittest
import wth
from mock import patch

class TestWth(unittest.TestCase):
    def test_wth(self):
        with patch('requests.get') as mock_requests:
            mock_requests.return_value="123"
            assert wth.wth1("http://www.google.com") == "123"

    @patch('requests.get')
    def test_method2_wth(self, mock1):
        mock1.return_value = "123"
        assert wth.wth1("http://www.google.com") == "123"

    @patch('requests.get')
    def test_method3_wth_with_sideeffect(self, mock1):
        def side_effect(*args, **kwargs):
            raise Exception("oops")
        mock1.side_effect = side_effect
        try:
            wth.wth1("http://www.google.com") == "123"
        except Exception as e:
            assert True



#abstract decorator, class method decorator, static method decorator
class A(object):
    def foo(self, x):
        print "executing foo(%s, %s)" % (self, x)

    @classmethod
    def class_foo(cls, x):
        print "executing class_foo(%s, %s)" % (cls, x)

    @staticmethod
    def static_foo(x):
        print "executing static_foo(%s)" % x    

a = A()

#normal class method have self passed in as first argument
a.foo(1)
# executing foo(<__main__.A object at 0xb7dbef0c>,1)
#With classmethods, the class of the object instance is implicitly passed as the first argument instead of self.

#class method has class method passed in as first argument
a.class_foo(1)
# executing class_foo(<class '__main__.A'>,1)
#You can also call class_foo using the class. In fact, if you define something to be a classmethod, it is probably because you intend to call it from the class rather than from a class instance. A.foo(1) would have raised a TypeError, but A.class_foo(1) works just fine:

#now we can call without instantiate a class
A.class_foo(1)
# executing class_foo(<class '__main__.A'>,1)
#One use people have found for class methods is to create inheritable alternative constructors.

#staticmethod doesn't have self or cls passed to it, it is just a normal function
#With staticmethods, neither self (the object instance) nor  cls (the class) is implicitly passed as the first argument. They behave like plain functions except that you can call them from an instance or the class:

a.static_foo(1)
# executing static_foo(1)

#also, static method can be called without instantiate a class
A.static_foo('hi')
# executing static_foo(hi)
Staticmethods are used to group functions which have some logical connection with a class to the class.


#property decorator, it makes a method to act as a variable of a class, we can use cls.var1=new_value and del clas.var1 to access setter and getter, exmaple below
class C(object):
    def __init__(self):
        self._x = None

    @property
    #use cls.x to retrieve the value
    def x(self):
        """I'm the 'x' property."""
        return self._x

    @x.setter
    #use cls.x = new_value
    def x(self, value):
        self._x = value

    @x.deleter
    #use del cls.x to delete the value
    def x(self):
        del self._x


#python logging
import logging

logging.basicConfig(level = logging.DEBUG) #logging.DEBUG is 10 INFO is 20, increaed by 10
#logging.basicConfig(filename = 'test.log', level = logging.DEBUG) #this will write log to the file named test.log in appending
#logging.basicConfig(filename = 'test.log', level = logging.DEBUG, format = '%(asctime)s:%(levelname)s:%(message)s') #this will write log to the file named test.log in appending


def add(x,y):
    return x + y
add_result = add(1,2)
logging.warning('result of add is xxx')
#logging.debug("123")--> this prints info, need to set log level to lower for this info to work

"""
Level	Numeric value
CRITICAL	50
ERROR	40
WARNING	30
INFO	20
DEBUG	10
NOTSET	0
"""
#logging would by default writing to root logger, use getLogger to change where it should write to, logger would fall back to root if no other logger specified
logger = logging.getLogger(__name__) #if run in main the name would be main, module then module
logger.setLevel(logging.INFO) #or file_handler.setLevel(logging.INFO), samething, but file_handler logging level only stick with file_handler
file_handler = logging.FileHandler('employee.log')
formatter = logging.Formatter('%(asctime)s:%(levelname)s:%(message)s')
logger.addHandler(file_handler)
logger.setFormatter(formatter)
logger.info("test123") #here need to use logger instad of default logging

#stream handler, it will print to console
stream_handler = logging.StreamHandler() #use this as the same of file handler


#pip isntall from a file
pip install -r path_to_pip_dependency_files


# python dates meaning with code
# time format
Code	Meaning	Example
%a	Weekday as locale’s abbreviated name.	Mon
%A	Weekday as locale’s full name.	Monday
%w	Weekday as a decimal number, where 0 is Sunday and 6 is Saturday.	1
%d	Day of the month as a zero-padded decimal number.	30
%-d	Day of the month as a decimal number. (Platform specific)	30
%b	Month as locale’s abbreviated name.	Sep
%B	Month as locale’s full name.	September
%m	Month as a zero-padded decimal number.	09
%-m	Month as a decimal number. (Platform specific)	9
%y	Year without century as a zero-padded decimal number.	13
%Y	Year with century as a decimal number.	2013
%H	Hour (24-hour clock) as a zero-padded decimal number.	07
%-H	Hour (24-hour clock) as a decimal number. (Platform specific)	7
%I	Hour (12-hour clock) as a zero-padded decimal number.	07
%-I	Hour (12-hour clock) as a decimal number. (Platform specific)	7
%p	Locale’s equivalent of either AM or PM.	AM
%M	Minute as a zero-padded decimal number.	06
%-M	Minute as a decimal number. (Platform specific)	6
%S	Second as a zero-padded decimal number.	05
%-S	Second as a decimal number. (Platform specific)	5
%f	Microsecond as a decimal number, zero-padded on the left.	000000
%z	UTC offset in the form +HHMM or -HHMM (empty string if the the object is naive).	
%Z	Time zone name (empty string if the object is naive).	
%j	Day of the year as a zero-padded decimal number.	273
%-j	Day of the year as a decimal number. (Platform specific)	273
%U	Week number of the year (Sunday as the first day of the week) as a zero padded decimal number. All days in a new year preceding the first Sunday are considered to be in week 0.	39
%W	Week number of the year (Monday as the first day of the week) as a decimal number. All days in a new year preceding the first Monday are considered to be in week 0.	39
%c	Locale’s appropriate date and time representation.	Mon Sep 30 07:06:05 2013
%x	Locale’s appropriate date representation.	09/30/13
%X	Locale’s appropriate time representation.	07:06:05
%%	A literal '%' character.	%



#converts datestring to datetime with timezone
datetime.strptime(date_string, format)[0:6]))
time.strptime(date_string, format)[0:6]))

# converts datetime obj to str
datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))


#lru cache in functools
@functools.lru_cache(maxsize=100)


#bell = [[0] * n] * n
#this init of an array is error prone, it looks like a pointer to object '0' is copied n*n times instead of a new '0' object created n*n times

#flat_map
flat_map = itertools.chain.from_iterable(sum_matrix)


#install package in develop mode
pip install -e ./PACKAGE_PATH

#expand a list
*arr
a= [1,2,3, *b] # this expands b arr into a

#type annotation
##any type
#T = TypeVar('T')


#ordered dict in collections library
## it has update, get and move_to_end method, this is a perfect implementation of LRU
Out[5]: OrderedDict()
In [6]: a.update({"a":1})
In [8]: a.update({"b":2})

In [9]: a
Out[9]: OrderedDict([('a', 1), ('b', 2)])

In [10]: a.get('a')
Out[10]: 1

In [13]: a.move_to_end('b', last = False)

In [14]: a
Out[14]: OrderedDict([('b', 2), ('a', 1)])




# python Set, set
a = {'a', 'b'}
a.add('c')
a.remove('a')
a.discard('d') # discard would not raise error if element does not exist in it

# difference of two sets
set_A.difference(set_B) # for (A - B)
set _B.difference(set_A) # for (B - A)


# iterate through pandas framework
pandas_gen = pandas_res.iterrows() # this yields a generator
for index, row in pandas_gen:
  print(row['column1'])


# check if pandas empty
df.empty

# insert an array to be as a new column for pandas df
# df.insert(2, "Age", [21, 23, 24, 21], True) <-- 2 is the column index, age is the colun name, last is the actual data


# pandas new df example
new_df = pandas.DataFrame([{"a":1,"b":2,"c":3},{"a":11,"b":22,"c":33}])

# call parent's method from a child
class Foo(Bar):
    def baz(self, arg):
        return super(Foo, self).baz(arg)

# remove quotes from string
'""""hello'.lstrip('"') = 'hello'

# read first few lines of a file
from itertools import islice
head = list(islice(f, 5))

# decompress python stream
d = zlib.decompressobj(16 + zlib.MAX_WBITS)
file_content = ""
with input_file.open(mode='r') as f:
    for chunk in f:
        file_content += d.decompress(chunk)
return io.BytesIO(file_content)


# sftp
import paramiko
transport = paramiko.Transport((host, port))
transport.start_client()
transport.auth_password(username, password)
client = paramiko.SFTPClient.from_transport(transport)
self.client.stat(remotepath)  # check if remote path exists
self.client.open(remotepath)  # opens the file
self.client.listdir(remotepath)  # list all files in a dir
self.client.listdir_attr(remotepath)  # list attribute of a dir
self.client.get(remote_path, local_path)  # download file to local_path

paramiko.sftp.readinto(buffer)  # fill the entire buffer with the file bytes


progress = round(total_read_bytes / file_size, 4) * 100  # good example of file progress calculation

# ipython debug
# pip isntall ipdb # <--- ipython debugger
# %pdb <---- this will turn on ipython automatic debug mode
import ipdb; ipdb.set_trace()  # <--- this will enable ipython debug mode

# get exception type and message
a=Exception("123")
type(a).__name__ # this only print exceptino type
type(a).message # this only prints message

# cannot decode 0x ascii error
# this is normally caused by python implicit string conversion, below invoke encode from a string, but encode cannot encode string, it can only encode unicode string, so python has to decode the string to unicode first with decode() and this is why it blow up, because default decoder cannot decode chinese character
"你好".encode('utf-8')  # this blows up
# encode converts a unicode object to a string object. But here you have invoked it on a string object (because you don't have the u). So python has to convert the string to a unicode object first. So it does the equivalent of
"你好".decode().encode('utf-8')
# But the decode fails because the string isn't valid ascii. That's why you get a complaint about not being able to decode.




# add leading zero
#In Python 2 you can do:
print "%02d" % (1,)
#Basically % is like printf or sprintf.
#For Python 3.+ the same behavior can be achieved with:
print("{:02d}".format(1))
#For Python 3.6+ the same behavior can be achieved with f-strings:
print(f"{1:02d}")

# md5
import hashlib
m = hashlib.md5()
m.update('any_string')
# md5_str = m.digest()  # this output bytes
md5_str = m.hexdigest() # this output string


# upload s3 file using boto3
import boto3
s3 = boto3.resource('s3')
def upload_file_to_S3(filename, key, bucket_name):
    s3.Bucket(bucket_name).upload_file(filename, key)


# __call__ difference with __init__,  call is instantiated when the instance of the class is called with ()
class Foo:
    def __call__(self, a, b, c):
        # ...

x = Foo()
x(1, 2, 3) # __call__


# abc meta creates abstract calss, subclass must implement abstract method
from abc import ABC, abstractmethod
 
class AbstractClassExample(ABC):
 
    def __init__(self, value):
        self.value = value
        super().__init__()
    
    @abstractmethod
    def do_something(self):
        pass
# @property needs to be before abstractmethod
class C(ABC):
    @property
    @abstractmethod
    def my_abstract_property(self):


# a simple implementation of abstrac class and abstract property
# currently, termux python seems doesn't raise exception when one abstract method is not implemented, so better add raise NotImplemented error in abstractclass to make sure it works
from abc import ABCMeta, abstractmethod, abstractproperty

# in python3, use this line class A(object, metaclass=ABCMeta): and we don't need __metaclass__=ABCMeta
class A(object):
    __metaclass__ = ABCMeta
    # abstractproperty force subclass to implement this
    @abstractproperty
    def q(self):
        pass

    @abstractmethod
    def a(self):
          pass

    def b(self):
        print("b")


class B(A):
    def a(self):
        print("a")
    def q(self):
        return 'q'



b = B()
b.a()
b.b()

print(b.q())



# multiprocessing
import multiprocessing
print("Number of cpu : ", multiprocessing.cpu_count())

# Process will create a process waiting to run
p = Process(target=self.run_func, args=(name,))
# this runs the process
p.start()
# join must be called for process to end
p.join(self.query_timeout)
if p.is_alive():
    p.terminate()
    getlogger().error("Timed out waiting for {}s for query {}".format(str(self.query_timeout), self.query()))

self.mark_done()

# multiprocessing queue
from multiprocessing import Queue

colors = ['red', 'green', 'blue', 'black']
cnt = 1
# instantiating a queue object
queue = Queue()
print('pushing items to queue:')
for color in colors:
    print('item no: ', cnt, ' ', color)
    queue.put(color)
    cnt += 1

print('\npopping items from queue:')
cnt = 0
while not queue.empty():
    print('item no: ', cnt, ' ', queue.get())
    cnt += 1


# =============multiprocess code example
from multiprocessing import Lock, Process, Queue, current_process
import time
import queue # imported for using queue.Empty exception


def do_job(tasks_to_accomplish, tasks_that_are_done):
    while True:
        try:
            '''
                try to get task from the queue. get_nowait() function will 
                raise queue.Empty exception if the queue is empty. 
                queue(False) function would do the same task also.
            '''
            task = tasks_to_accomplish.get_nowait()
        except queue.Empty:

            break
        else:
            '''
                if no exception has been raised, add the task completion 
                message to task_that_are_done queue
            '''
            print(task)
            tasks_that_are_done.put(task + ' is done by ' + current_process().name)
            time.sleep(.5)
    return True


def main():
    number_of_task = 10
    number_of_processes = 4
    tasks_to_accomplish = Queue()
    tasks_that_are_done = Queue()
    processes = []

    for i in range(number_of_task):
        tasks_to_accomplish.put("Task no " + str(i))

    # creating processes
    for w in range(number_of_processes):
        p = Process(target=do_job, args=(tasks_to_accomplish, tasks_that_are_done))
        processes.append(p)
        p.start()

    # completing process
    for p in processes:
        p.join()

    # print the output
    while not tasks_that_are_done.empty():
        print(tasks_that_are_done.get())

    return True


if __name__ == '__main__':
    main()


# ===========end of multiprocess code example

# multiprocessing pool
from multiprocessing import Pool

import time

work = (["A", 5], ["B", 2], ["C", 1], ["D", 3])


def work_log(work_data):
    print(" Process %s waiting %s seconds" % (work_data[0], work_data[1]))
    time.sleep(int(work_data[1]))
    print(" Process %s Finished." % work_data[0])


def pool_handler():
    p = Pool(2)
    p.map(work_log, work)


if __name__ == '__main__':

# multiprocessing checking timeout and if timeout, kill all subprocesses
TIMEOUT = 5 
start = time.time()
while time.time() - start <= TIMEOUT:
    if any(p.is_alive() for p in procs):
        time.sleep(.1)  # Just to avoid hogging the CPU
    else:
        # All the processes are done, break now.
        break
else:
    # We only enter this if we didn't 'break' above.
    print("timed out, killing all processes")
    for p in procs:
        p.terminate()
        p.join()


# returns a contextlib to close a file after with statement
with contextlib.closing(connect("user", "host", "port", None)) as sftp:
    do_something

# memory profiler
# pip install -U memory_profiler
@profile  # use this to add profile to your function


# feature introduced in python 3.0 as a pointer to an object, let's say a string, so when view = memoryview(s), view[1:3] will not do extra copying of string
memoryview
below is an exmaple of minimum memory needed read and write process
@profile
def read_random():
    with open("/dev/urandom", "rb") as source:
        content = source.read(1024 * 10000)
        content_to_write = memoryview(content)[1024:]
    print("Content length: %d, content to write length %d" %
          (len(content), len(content_to_write)))
    with open("/dev/null", "wb") as target:
        target.write(content_to_write)

if __name__ == '__main__':
    read_random()

# use memoryview in socket send traffic
import socket
s = socket.socket(…)
s.connect(…)
# Build a bytes object with more than 100 millions times the letter `a`
data = b"a" * (1024 * 100000)
mv = memoryview(data)
while mv:
    sent = s.send(mv)
    # Build a new memoryview object pointing to the data which remains to be sent
    mv = mv[sent:]


# reuse buffer, in this case, we have buffer that could be used to read over and over again, if we want to speed up things we can add memory view to it to improve it
>>> ba = bytearray(8)
>>> ba
bytearray(b'\x00\x00\x00\x00\x00\x00\x00\x00')
>>> with open("/dev/urandom", "rb") as source:
...     source.readinto(ba)
... 
8
>>> ba
bytearray(b'`m.z\x8d\x0fp\xa1')

# time a function in python
time.time()

# fillna replace the na with 'Unknown' string
lambda _: _.fillna('Unknown', inplace=True)


# hex to string in python3
In [9]: import binascii

In [10]: binascii.unhexlify('7061756c')
Out[10]: b'paul'

In [11]:

# hex to string in python 2
'7061756c'.decode('hex')

# datetime subtract a few days
from datetime import datetime, timedelta
d = datetime.today() - timedelta(days=days_to_subtract)

# disable py.test warning
py.test --disable-pytest-warnings test_file_path

# any list item in a list
any(x in a for x in b)

# really long line string in python
a = (
'a'
'b'
'c'
)  # this will get you 'abc'


# cast from string to bytes
bytes('0aff', 'utf-8') # this utf-8 tells python should treat this '0a' as one byte and 'ff' as one byte, not treat '0aff' as two bytes that repeasents as 1 character in utf-16

# raw input is what user inputs, python3 renamed it to input
input = raw_input('$ ')  # a input box showing $ 

# reload module in python2 it is called reload
reload(module_name)
# python3
from importlib import reload

# convert hex to int
s = '000a'
i = int(s, 16)  # result is 10

# hex to bytes
bytearray.fromhex('030f')  # this will produces bytes

# bytes to hex
bytedata1.hex()

# unpack bytes
# struct.unpack_from
# < means littleendian while > means bigendian, i means integer
struct.unpack_from('<i', bytearray1)  # integer requires 4 bytes


# string to hex
hex(ord("a"))  # string "a" needs to convert to ord(int) first, then converts to hex

# padding string
'hi'.ljust(10, 'p')  # it would return 'hi--------'

# requests streaming example
import requests
import json
r = requests.get('https://httpbin.org/stream/20', stream=True)

if r.encoding is None:
    r.encoding = 'utf-8'

for line in r.iter_lines(decode_unicode=True):  # iter_lines can run without decode, can add chunk_size = big_number_here to speed up
    if line:
        print(json.loads(line))  # requests have already splits the lines for you, and it stripped new line character

# load json from file
with open(full_file_path, 'r') as f:
  json.load(f)



# bitwise operation
# x << y Returns x with the bits shifted to the left by y places (and new bits on the right-hand-side are zeros). This is the same as multiplying x by 2**y.
# x >> yReturns x with the bits shifted to the right by y places. This is the same as //'ing x by 2**y.
# x & y Does a "bitwise and". Each bit of the output is 1 if the corresponding bit of x AND of y is 1, otherwise it's 0.
# x | y Does a "bitwise or". Each bit of the output is 0 if the corresponding bit of x AND of y is 0, otherwise it's 1.
# ~ xReturns the complement of x - the number you get by switching each 1 for a 0 and each 0 for a 1. This is the same as -x - 1.
# x ^ yDoes a "bitwise exclusive or". Each bit of the output is the same as the corresponding bit in x if that bit in y is 0, and it's the complement of the bit in x if that bit in y is 1.


# add timezone
dt.replace(tzinfo=pytz.timezone('America/New_York')) 

# get local timezone from system
from tzlocal import get_localzone



# print curly brace in python format string
In [6]: a = '{}={{{}}}'.format('123', '234')
In [7]: a
Out[7]: '123={234}'


# pdb some function key shows as characters
pip install gnureadline

# microsecond format
'%Y-%m-%d %H:%M:%S.%f'

# runs a simple file http server
python -m SimpleHTTPServer


download_path, _ = urllib.request.urlretrieve(url, file_abs_path, self.download_progress)

def download_progress(self, count, blockSize, totalSize):
  percent = int(count * blockSize * 100 / totalSize)
  sys.stdout.write("\r" + "...%d%%" % percent)
  sys.stdout.flush()

# find module path
import requests
print(requests.__file__)

# get first row of dataframe
df.iloc[0]

# dataframe to json or to dict
df.to_dict()

# dataframe to json string
df.to_json()
# fast do datetime covert to date
datetime.date(*map(int,self.day.split('-')))


# time format
%a Locale’s abbreviated weekday name.

%A Locale’s full weekday name.

%b Locale’s abbreviated month name.

%B Locale’s full month name.

%c Locale’s appropriate date and time representation.

%d Day of the month as a decimal number [01,31].

%H Hour (24-hour clock) as a decimal number [00,23].

%I Hour (12-hour clock) as a decimal number [01,12].

%j Day of the year as a decimal number [001,366].

%m Month as a decimal number [01,12].

%M Minute as a decimal number [00,59].

%p Locale’s equivalent of either AM or PM.

(1) %S Second as a decimal number [00,61].

(2) %U Week number of the year (Sunday as the first day of the week) as a decimal number [00,53]. All days in a new year preceding the first Sunday are considered to be in week 0.

(3) %w Weekday as a decimal number [0(Sunday),6].

%W Week number of the year (Monday as the first day of the week) as a decimal number [00,53]. All days in a new year preceding the first Monday are considered to be in week 0.

(3) %x Locale’s appropriate date representation.
%X Locale’s appropriate time representation.

%y Year without century as a decimal number [00,99].  
%Y Year with century as a decimal number.

%Z Time zone name (no characters if no time zone exists).

%% A literal '%' character.

# write to gzip file
with gzip.open(data_path, 'w') as f:
  f.write(json.dumps(data_json))


# dict sort by key or value
mydict = {'carl':40, 'alan':2, 'bob':1, 'danny':3}

print ('Sort by keys:')
for key in sorted(mydict.keys()):
    print ("%s: %s" % (key, mydict[key]))

print ('Sort by items:')
for key, value in sorted(mydict.items(), key=lambda item: (item[1], item[0])):
    print ("%s: %s" % (key, value))
